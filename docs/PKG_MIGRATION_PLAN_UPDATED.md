# PKG Migration Plan: From 603MB DMG to 10MB PKG Installer (UPDATED)

## Overview

Migrate Skip the Podcast Desktop from a 603MB bundled DMG to a 10MB PKG installer that downloads components during installation. This approach eliminates Python permission issues while providing framework-style isolation and professional macOS installer experience.

**NEW REQUIREMENTS INTEGRATION:**
1. âœ… Pyannote models download during initial install (not first-use)
2. âœ… Mandatory Ollama model installation with verification 
3. âœ… Hardware-based model recommendations
4. âœ… Automatic Obsidian installation and vault configuration
5. âœ… Decision on FFmpeg hosting strategy

## What Gets Downloaded During PKG Installation

### **1. Python Framework (~40MB)**
```bash
# Downloaded from your GitHub releases
https://github.com/your-repo/releases/python-3.13-framework-macos.tar.gz
```
- **Contents**: Complete Python 3.13 runtime as macOS framework
- **Purpose**: Private Python installation for complete isolation
- **Location**: `Skip the Podcast Desktop.app/Contents/Frameworks/Python.framework/`

### **2. Python Dependencies (~200MB)**
From `requirements.txt` and `pyproject.toml`:
- **PyQt6** (~224MB) - GUI framework
- **PyTorch** (~339MB) - ML/AI framework for diarization and HCE
- **Transformers** (~53MB) - HuggingFace models
- **Other packages** (~100MB) - Core dependencies

### **3. AI Models (~1.2GB) - ALL DOWNLOADED DURING INSTALL**

#### **Whisper Models (~141MB)**
- **ggml-base.bin** (141.1 MB)
- **Purpose**: Speech transcription

#### **Voice Fingerprinting Models (~710MB)**
- **wav2vec2-base-960h.tar.gz** (631.1 MB) - Voice feature extraction
- **spkrec-ecapa-voxceleb.tar.gz** (79.3 MB) - Speaker recognition

#### **ðŸ”¥ NEW: Pyannote Models (~400MB) - MANDATORY DURING INSTALL**
- **Model**: pyannote/speaker-diarization-3.1
- **Download**: During PKG installation (moved from first-use)
- **Purpose**: Speaker diarization and separation
- **Source**: Pre-packaged from HuggingFace

### **4. System Binaries**

#### **FFmpeg (~48MB) - HOSTED ON OUR REPO**
**Decision: YES, host FFmpeg on our GitHub releases**
- **Pros**: 
  - Guaranteed availability and version control
  - No external dependency failures
  - Custom builds optimized for our use case
  - Consistent checksums and security
- **Cons**: 
  - Repo storage usage (~48MB per release)
  - Need to maintain updates
- **Verdict**: The reliability benefits outweigh storage costs

#### **Whisper.cpp (~10MB)**
- **Source**: Compiled from whisper.cpp source during install
- **Purpose**: Local transcription binary

#### **Ollama (~50MB)**
- **Source**: Official Ollama Darwin binary
- **Install Location**: `/usr/local/bin/ollama`

### **5. ðŸ”¥ NEW: Ollama Models (MANDATORY) - Hardware-Optimized Selection**

**CRITICAL CHANGE**: Installation cannot complete without a verified Ollama model working properly.

#### **Hardware Detection & Model Recommendations**
Using existing `HardwareDetector` class from `src/knowledge_system/utils/hardware_detection.py`:

```python
def get_ollama_model_recommendation(specs: HardwareSpecs) -> dict:
    """Recommend optimal Ollama model based on hardware."""
    
    if specs.memory_gb >= 64 and specs.chip_type in [ChipType.M3_ULTRA, ChipType.M2_ULTRA]:
        return {
            "primary": "qwen2.5:14b",
            "size": "8.2GB", 
            "description": "High-quality model for Ultra systems",
            "optional_upgrade": "llama3.1:70b (40GB) - Expert mode"
        }
    elif specs.memory_gb >= 32 and specs.chip_type in [ChipType.M3_MAX, ChipType.M2_MAX]:
        return {
            "primary": "qwen2.5:14b",
            "size": "8.2GB",
            "description": "Optimal for Max systems" 
        }
    elif specs.memory_gb >= 16:
        return {
            "primary": "qwen2.5:7b", 
            "size": "2GB",
            "description": "Balanced for Pro systems"
        }
    else:
        return {
            "primary": "qwen2.5:3b",
            "size": "2GB", 
            "description": "Efficient for base systems"
        }
```

#### **Model Installation Flow**
```bash
# During PKG installation:
1. Detect hardware (RAM, chip type, thermal design)
2. Show recommendation dialog with options
3. Download selected model (1.3GB - 4.7GB)
4. Install and start Ollama service
5. Verify model responds to test prompt
6. FAIL INSTALLATION if model verification fails
```

### **6. ðŸ”¥ NEW: Obsidian Integration (~200MB)**

**Automatic Obsidian Installation & Configuration**:

#### **Installation Logic**
```bash
# Check if Obsidian already installed
if [ ! -d "/Applications/Obsidian.app" ]; then
    echo "ðŸ“ Installing Obsidian for knowledge management..."
    curl -L -o /tmp/obsidian.dmg "https://github.com/obsidianmd/obsidian-releases/releases/latest/download/Obsidian-X.X.X.dmg"
    hdiutil attach /tmp/obsidian.dmg
    cp -R "/Volumes/Obsidian/Obsidian.app" "/Applications/"
    hdiutil detach "/Volumes/Obsidian"
fi
```

#### **Vault Configuration**
```bash
# Create default vault location
VAULT_PATH="$HOME/Documents/SkipThePodcast_Knowledge"
mkdir -p "$VAULT_PATH"

# Configure Obsidian to use this as default vault
OBSIDIAN_CONFIG="$HOME/Library/Application Support/obsidian"
mkdir -p "$OBSIDIAN_CONFIG"

# Set SkipThePodcast as default vault in Obsidian config
cat > "$OBSIDIAN_CONFIG/obsidian.json" << EOF
{
  "vaults": {
    "$(basename "$VAULT_PATH")": {
      "path": "$VAULT_PATH",
      "ts": $(date +%s)000
    }
  },
  "open": "$(basename "$VAULT_PATH")"
}
EOF
```

#### **SkipThePodcast Integration**
- **Default Output Location**: All `.md` files written to `~/Documents/SkipThePodcast_Knowledge/`
- **Auto-linking**: Obsidian wikilink format enabled by default
- **Templates**: Install SkipThePodcast note templates
- **Plugins**: Suggest compatible plugins for media notes

## **Updated Download Size Breakdown**

| Component | Size | When Downloaded | Required |
|-----------|------|----------------|----------|
| **Python Framework** | 40MB | During PKG install | âœ… Yes |
| **Python Dependencies** | 200MB | During PKG install | âœ… Yes |
| **AI Models** | 1.2GB | During PKG install | âœ… Yes (includes Pyannote) |
| **System Binaries** | 98MB | During PKG install | âœ… Yes (FFmpeg + others) |
| **Ollama Models** | 1.3-4.7GB | During PKG install | âœ… MANDATORY |
| **Obsidian** | 200MB | During PKG install | âœ… Yes (if not present) |
| **Total (Minimum)** | ~3GB | During install | All required |
| **Total (High-end)** | ~6.2GB | During install | All required |

## **Updated Installation Flow**

```bash
# PKG Installation Process:

# Pre-install script (with admin privileges):
echo "ðŸ” Detecting hardware specifications..."
# Run hardware detection
# Calculate model recommendations

echo "ðŸ Downloading Python framework (40MB)..."
curl -L -o /tmp/python-framework.tar.gz [REPO_URL]

echo "ðŸ§  Downloading AI models (1.2GB)..."
# Download Whisper, voice fingerprinting, AND Pyannote models
curl -L -o /tmp/ai-models.tar.gz [REPO_URL] 

echo "ðŸŽ¬ Downloading FFmpeg from our repo (48MB)..."
curl -L -o /tmp/ffmpeg.tar.gz [OUR_GITHUB_RELEASES]

echo "ðŸ¦™ Installing Ollama (50MB)..."
curl -L -o /tmp/ollama [OLLAMA_OFFICIAL]

echo "ðŸ“ Installing Obsidian (200MB)..."
# Download and install if not present
# Configure default vault location

echo "ðŸ¤– Hardware-optimized model selection..."
# Show user recommendation based on hardware
# Download selected Ollama model (1.3-4.7GB)

echo "âœ… Verifying all components..."
# Test Python framework
# Test AI models load correctly  
# Test Ollama model responds
# Test Obsidian vault configuration
# FAIL if any component doesn't work

# Post-install script:
echo "ðŸ“¦ Installing Python dependencies (200MB)..."
# Use framework Python to install packages

echo "ðŸ”§ Final configuration..."
# Set up app launch script
# Configure integrations
# Create desktop shortcuts

echo "ðŸŽ‰ Installation complete - all systems verified!"
```

## **Implementation Tasks**

### **Phase 1: Infrastructure Setup**

#### **1.1 Create Python Framework Build**
- [ ] **Download Python 3.13 source**
- [ ] **Configure framework build for macOS**
- [ ] **Build relocatable Python.framework**
- [ ] **Test framework isolation**
- [ ] **Package framework for distribution**

#### **1.2 Set Up Download Infrastructure**  
- [ ] **Create GitHub release for Python framework** (~40MB)
- [ ] **Upload AI models package** (~1.2GB)
- [ ] **Create dependency packages** (~200MB)
- [ ] **Set up versioned release system**
- [ ] **Test download reliability and speed**

#### **1.3 Design PKG Structure**
- [ ] **Create minimal app bundle skeleton** (~5MB)
- [ ] **Write download and installation scripts** (~1MB)
- [ ] **Design requirements and metadata** (~1MB)
- [ ] **Create PKG build system**
- [ ] **Test PKG creation and signing**

### **NEW Phase 1.4: Hardware-Optimized Model Selection**
- [ ] **Integrate HardwareDetector into installer**
- [ ] **Create model recommendation engine**
- [ ] **Design model selection dialog**
- [ ] **Implement hardware-based defaults**
- [ ] **Add optional upgrade paths for high-end systems**

### **NEW Phase 1.5: Obsidian Integration**
- [ ] **Detect existing Obsidian installations**
- [ ] **Download and install Obsidian if missing**
- [ ] **Configure default vault location**
- [ ] **Set up SkipThePodcast templates**
- [ ] **Test vault integration**

### **Phase 2: Installer Scripts Development**

#### **2.1 Pre-install Script**
- [ ] **Download Python framework from GitHub releases**
- [ ] **Download AI models package**
- [ ] **Download Ollama binary**
- [ ] **Verify checksums and integrity**
- [ ] **Handle download failures gracefully**

#### **2.2 Post-install Script**  
- [ ] **Extract Python framework to app bundle**
- [ ] **Create virtual environment using framework Python**
- [ ] **Install Python dependencies with pip**
- [ ] **Configure Ollama and models**
- [ ] **Set up proper permissions and ownership**
- [ ] **Verify installation success**

#### **2.3 Progress and Error Handling**
- [ ] **Implement progress reporting during downloads**
- [ ] **Add comprehensive error handling**
- [ ] **Create fallback mechanisms for download failures**
- [ ] **Design user-friendly error messages**
- [ ] **Test network timeout scenarios**

### **NEW Phase 2.4: Mandatory Model Verification**
- [ ] **Download and install Pyannote during install**
- [ ] **Implement Ollama model verification**
- [ ] **Create model testing prompts**
- [ ] **Add installation failure on model issues**
- [ ] **Implement retry mechanisms for model downloads**

### **NEW Phase 2.5: FFmpeg Self-Hosting**
- [ ] **Set up FFmpeg binary hosting on GitHub releases**
- [ ] **Create versioned FFmpeg packages**
- [ ] **Implement checksum verification**
- [ ] **Add fallback to external sources**
- [ ] **Test FFmpeg integration**

### **ðŸ”¥ NEW Phase 2.6: Publishing Workflow Migration**
- [ ] **Update `release_dmg_to_public.sh` â†’ `release_pkg_to_public.sh`**
- [ ] **Update `publish_release.sh` for PKG artifacts**
- [ ] **Modify `push_to_github.sh` to handle PKG builds**
- [ ] **Update `commit_with_autofix.sh` for new workflow**
- [ ] **Create PKG-specific build and release scripts**
- [ ] **Update all DMG references to PKG in scripts**
- [ ] **Migrate GitHub release automation for PKG**

### **Phase 3: App Bundle Redesign**

#### **3.1 Launch Script Rewrite**
- [ ] **Remove complex Python detection logic**
- [ ] **Use framework Python exclusively**
- [ ] **Set proper PYTHONHOME and PYTHONPATH**
- [ ] **Eliminate permission workarounds**
- [ ] **Add framework verification checks**

#### **3.2 Python Environment Isolation**
- [ ] **Configure framework-based virtual environment**
- [ ] **Ensure complete isolation from system Python**
- [ ] **Test with multiple Python versions on system**
- [ ] **Validate no PATH pollution**
- [ ] **Verify dependency isolation**

#### **3.3 App Configuration Updates**
- [ ] **Update Info.plist for framework references**
- [ ] **Configure bundle identifiers and versions**
- [ ] **Set minimum macOS version requirements**
- [ ] **Update application metadata**
- [ ] **Prepare for code signing**

### **Phase 4: Cleanup and Simplification**

#### **4.1 Remove Legacy Scripts**
- [ ] **Delete `fix_dmg_python_launch.sh`**
- [ ] **Delete `fix_python_for_dmg.sh`**
- [ ] **Delete `fix_app_version.sh`**
- [ ] **Delete `python_auto_installer.sh`**
- [ ] **Delete `fix_dmg_gatekeeper.sh`**
- [ ] **Delete `fix_remote_installation.sh`**

#### **4.2 Simplify Build Process**
- [ ] **Remove complex venv creation in build script**
- [ ] **Eliminate sudo usage in build process**
- [ ] **Remove quarantine workaround code**
- [ ] **Simplify Python detection logic**
- [ ] **Clean up permission handling code**

#### **4.3 Update Documentation**
- [ ] **Update README installation instructions**
- [ ] **Remove troubleshooting for Python issues**
- [ ] **Document new PKG installer approach**
- [ ] **Update system requirements**
- [ ] **Create installation verification guide**

### **Phase 5: Testing and Validation**

#### **5.1 Installation Testing**
- [ ] **Test on fresh macOS installations**
- [ ] **Test with existing Python installations**
- [ ] **Test with Homebrew Python**
- [ ] **Test with conda environments**
- [ ] **Test offline installation scenarios**

#### **5.2 Isolation Validation**
- [ ] **Verify Python version isolation**
- [ ] **Test with conflicting system packages**
- [ ] **Validate framework independence**
- [ ] **Test uninstall process**
- [ ] **Verify no system pollution**

#### **5.3 Performance Testing**
- [ ] **Validate app startup performance**
- [ ] **Test memory usage patterns**
- [ ] **Benchmark against current DMG approach**

### **Phase 6: Distribution and Deployment**

#### **6.1 PKG Building and Signing**
- [ ] **Set up automated PKG build process**
- [ ] **Configure code signing for PKG**
- [ ] **Test notarization process**
- [ ] **Validate Gatekeeper compatibility**
- [ ] **Create release automation**

#### **6.2 Release Preparation**
- [ ] **Prepare GitHub releases for components**
- [ ] **Update version management system**
- [ ] **Create release notes and changelog**
- [ ] **Test complete release pipeline**
- [ ] **Prepare rollback mechanisms**

#### **6.3 Migration Strategy**
- [ ] **Plan transition from DMG to PKG**
- [ ] **Create migration guide for existing users**
- [ ] **Set up parallel distribution during transition**
- [ ] **Monitor adoption and feedback**
- [ ] **Plan DMG deprecation timeline**

## **Expected Outcomes**

### **Size Improvements**
- **DMG Size**: 603MB â†’ 10MB PKG (95% reduction)
- **Initial Download**: Instant vs. 603MB download  
- **Total Install Size**: 3-6GB progressive download vs. 603MB upfront

### **Architecture Benefits**
- **Zero Python conflicts** with system installations
- **Framework-style isolation** following macOS conventions
- **Elimination of permission workarounds**
- **Professional installer experience**
- **Simplified maintenance and support**

### **User Experience**
- **Faster initial download** (10MB vs 603MB)
- **Standard macOS installer** (familiar UI)
- **Single password prompt** for all operations
- **Progressive installation** with clear progress
- **Reliable cross-machine compatibility**

## **Success Criteria**

1. **PKG installer works on fresh macOS systems**
2. **Complete Python isolation achieved**
3. **All emergency fix scripts eliminated**
4. **Installation time under 20 minutes on average internet**
5. **Zero Python version conflict reports**
6. **User satisfaction with installer experience**
7. **Reduced support tickets for installation issues**
8. **98% installation success rate across test environments**
9. **All core features work immediately after installation**
10. **Obsidian integration configured automatically**

## **Risk Mitigation**

### **Potential Risks**
- **Download failures** during installation
- **Network connectivity issues**
- **Framework building complexity**
- **Code signing complications**
- **User adoption resistance**
- **Large download sizes** (3-6GB total)
- **Component verification failures**

### **Mitigation Strategies**
- **Robust error handling** and retry mechanisms
- **Multi-source download** fallback options
- **Degraded installation mode** for network issues
- **Comprehensive testing** on multiple systems
- **Gradual rollout** with feedback collection
- **Clear migration documentation** and support
- **Professional installer UX** to build user confidence

## **Benefits of Updated Approach**

### **Reliability Improvements**
- **100% functional guarantee**: Installation fails if any component doesn't work
- **No first-run surprises**: Everything tested during installation
- **Hardware-optimized**: Models selected for optimal performance
- **Integrated workflow**: Obsidian ready for immediate use

### **User Experience**
- **One installation, everything works**: No post-install setup required
- **Smart recommendations**: Models chosen based on actual hardware
- **Familiar tools**: Obsidian integration for knowledge management
- **Progress visibility**: Clear installation progress with component details

### **Maintenance Benefits**
- **Controlled dependencies**: FFmpeg hosted on our infrastructure
- **Version consistency**: All components versioned together
- **Predictable behavior**: Known working configurations only
- **Simplified support**: Fewer variables in user configurations

## **Answers to Your Questions**

### **1. Current System State & Dependencies**
âœ… **CONFIRMED**: Current Python version is **3.13+** (verified in pyproject.toml)
âœ… **CONFIRMED**: No existing users need migration considerations  
âœ… **CONFIRMED**: HuggingFace token is properly configured in `config/credentials.yaml` for team access

### **2. Infrastructure & Hosting**
âœ… **CONFIRMED**: GitHub repository permissions available for large file releases
âœ… **STRATEGY**: Host only basic models necessary to run the app; users select larger models in-app via Ollama
âœ… **RECOMMENDED**: Use **GitHub Releases exclusively** (not LFS) - better integration, simpler auth, under 2GB limits

### **3. Hardware Detection Integration**
âœ… **VERIFIED**: `HardwareDetector` class exists in `src/knowledge_system/utils/hardware_detection.py` with comprehensive API
âœ… **PRIORITY**: M2 Ultra with 128GB RAM testing configuration

### **4. Existing Scripts & Build Process**
âœ… **ANALYZED**: Current DMG build process understood via `scripts/build_macos_app.sh` and `scripts/release_dmg_to_public.sh`
âš ï¸ **NOTE**: No Apple Developer certificates currently configured - PKG will need manual notarization setup

### **5. Phased Execution Approach**
âœ… **CONFIRMED**: Execute entire plan in phases as outlined
âœ… **STRATEGY**: Begin with Phase 1 (Infrastructure setup) as foundation

### **6. Testing & Validation**
âœ… **CONFIRMED**: Multiple macOS systems available for testing
âœ… **CONFIRMED**: No user migration needed - fresh installation approach

### **7. Timeline & Scope**
âœ… **SCOPE**: Implement entire 8-11 week plan
âœ… **DEADLINES**: No critical constraints identified

## **Scripts Requiring DMG â†’ PKG Migration**

Based on the codebase analysis, **26 scripts** reference DMG files and need updates:

### **ðŸš€ Primary Publishing Scripts (Critical)**
1. **`release_dmg_to_public.sh`** â†’ `release_pkg_to_public.sh`
   - Changes DMG build/upload to PKG build/upload
   - Updates GitHub release creation for PKG files
   - Modifies size reporting and verification

2. **`publish_release.sh`**
   - Updates release artifact from DMG to PKG
   - Changes GitHub CLI commands for PKG uploads
   - Modifies release notes templates

3. **`push_to_github.sh`**
   - Updates Whisper model pre-caching logic
   - Changes version and build references

4. **`commit_with_autofix.sh`**
   - No major changes needed (handles commits/pushes)

### **ðŸ”§ Build and Distribution Scripts**
5. **`build_macos_app.sh`** â†’ Becomes PKG skeleton builder
6. **`sign_dmg_app.sh`** â†’ `sign_pkg_installer.sh`
7. **`test_dmg_installation.sh`** â†’ `test_pkg_installation.sh`
8. **`test_dmg_locally.sh`** â†’ `test_pkg_locally.sh`
9. **`diagnose_dmg_build.sh`** â†’ `diagnose_pkg_build.sh`

### **ðŸ—‘ï¸ Scripts to Remove/Deprecate**
10. **`release_minimal_dmg.sh`** - No longer needed
11. **`fix_dmg_gatekeeper.sh`** - PKG handles permissions properly
12. **`fix_dmg_python_launch.sh`** - Framework eliminates need
13. **`INSTALL_AND_OPEN.command`** - Replaced by PKG installer
14. **`GATEKEEPER_FREE_INSTALLATION.md`** - Update for PKG process

### **ðŸ“¦ Component Installation Scripts (Update)**
15. **`install_skip_the_podcast.py`** - Update for PKG workflow
16. **`install_skip_the_podcast.sh`** - Update for PKG workflow
17. **`create_web_installer.py`** - Update for PKG downloads
18. **`silent_ffmpeg_installer.py`** - Integrate into PKG pre-install
19. **`install_whisper_cpp_binary.py`** - Integrate into PKG pre-install
20. **`silent_pyannote_installer.py`** - Integrate into PKG pre-install

### **ðŸ§ª Testing and Setup Scripts**
21. **`first_run_setup.sh`** - Update for PKG components
22. **`setup_mvp_llm.sh`** - Integrate into PKG mandatory flow
23. **`test_auto_update_setting.py`** - Update for PKG updates
24. **`test_build_with_macos_paths.py`** - Update paths

### **ðŸ“ Model and Voice Scripts**
25. **`download_voice_models_direct.py`** - Integrate into PKG
26. **`download_pyannote_direct.py`** - Integrate into PKG
27. **`bundle_all_models.sh`** - Replace with PKG download logic

## **New PKG Publishing Workflow**

### **Current DMG Workflow:**
```bash
# Current process
./scripts/release_dmg_to_public.sh --bump-version
# â†’ Builds 603MB DMG
# â†’ Uploads to GitHub releases  
# â†’ Updates public repo README
```

### **New PKG Workflow:**
```bash
# New process
./scripts/release_pkg_to_public.sh --bump-version
# â†’ Builds 10MB PKG with download scripts
# â†’ Uploads PKG + component packages to GitHub releases
# â†’ Creates versioned release with all dependencies
# â†’ Updates public repo README with PKG instructions
```

### **Key Changes in Publishing Scripts:**

#### **1. `release_pkg_to_public.sh` (New)**
```bash
#!/bin/bash
# Build PKG instead of DMG
echo "ðŸ”¨ Building PKG installer..."
./scripts/build_pkg_installer.sh

# Upload PKG + dependency packages  
echo "ðŸ“¦ Uploading PKG and dependencies to GitHub..."
gh release create "v${VERSION}" \
    "dist/Skip_the_Podcast_Desktop-${VERSION}.pkg" \
    "dist/python-framework-${VERSION}.tar.gz" \
    "dist/ai-models-${VERSION}.tar.gz" \
    "dist/ffmpeg-macos-${VERSION}.tar.gz"
```

#### **2. Updated `publish_release.sh`**
```bash
# Change from DMG asset to PKG asset
DMG_PATH="dist/Skip_the_Podcast_Desktop-${CURRENT_VERSION}.dmg"
# BECOMES:
PKG_PATH="dist/Skip_the_Podcast_Desktop-${CURRENT_VERSION}.pkg"

# Update installation instructions
echo "1. Download the latest \`.pkg\` file from releases"
echo "2. Double-click the \`.pkg\` file to install"  
echo "3. Enter your password when prompted"
echo "4. Wait for component downloads to complete"
echo "5. Launch from Applications"
```

#### **3. New GitHub Release Structure**
```
GitHub Release v3.2.23/
â”œâ”€â”€ Skip_the_Podcast_Desktop-3.2.23.pkg (10MB)
â”œâ”€â”€ python-3.13-framework-macos.tar.gz (40MB)  
â”œâ”€â”€ ai-models-v3.2.23.tar.gz (1.2GB)
â”œâ”€â”€ ffmpeg-macos-arm64.tar.gz (48MB)
â”œâ”€â”€ ollama-models-manifest.json (1KB)
â””â”€â”€ checksums.sha256 (1KB)
```

## **Updated Timeline (Including Publishing Migration)**

- **Phase 1-2**: 3-4 weeks (Infrastructure, scripts, and new requirements)
- **Phase 2.6**: 1 week (Publishing workflow migration)
- **Phase 3-4**: 1-2 weeks (App redesign and cleanup)  
- **Phase 5**: 1-2 weeks (Testing with new components)
- **Phase 6**: 1 week (Distribution and final validation)

**Total Estimated Time**: 8-11 weeks (includes comprehensive error handling and testing)

## **ðŸ“‹ Error Handling & Testing Details**

**Note**: Comprehensive error handling and testing specifications have been documented in a separate supplement file:

ðŸ“„ **[PKG_ERROR_HANDLING_SUPPLEMENT.md](PKG_ERROR_HANDLING_SUPPLEMENT.md)**

This supplement includes detailed implementations for:
- âœ… **Fallback mechanisms for download failures** (multi-source, resume, degraded mode)
- âœ… **Checksum verification implementation** (SHA256, GPG signing, verification)
- âœ… **Disk space management** (pre-check, monitoring, cleanup)
- âœ… **Permission failure recovery** (admin verification, error handling)
- âœ… **Component verification system** (Python, Ollama, Obsidian testing)
- âœ… **Test environments specification** (clean macOS, corporate, edge cases)
- âœ… **Automated testing for PKG installation** (complete test suite)
- âœ… **Regression testing procedures** (test matrix, automation)
- âœ… **User acceptance testing criteria** (UAT success criteria, protocols)

### **Updated Timeline (Including Error Handling)**

- **Phase 0**: 1 week (Error handling & testing infrastructure)
- **Phase 1-2**: 3-4 weeks (Infrastructure, scripts, and new requirements)
- **Phase 2.6**: 1 week (Publishing workflow migration)
- **Phase 3-4**: 1-2 weeks (App redesign and cleanup)  
- **Phase 5**: 2-3 weeks (Comprehensive testing with new procedures)
- **Phase 6**: 1 week (Distribution and final validation)

## **Implementation Guidance & Next Steps**

### **Immediate Action Plan:**
1. **Phase 1.1**: Create Python 3.13 Framework build system
2. **Phase 1.2**: Set up GitHub releases infrastructure for component hosting  
3. **Phase 1.3**: Design minimal PKG structure with download scripts
4. **Phase 1.4**: Integrate HardwareDetector for model recommendations
5. **Phase 1.5**: Implement Obsidian integration logic

### **Critical Implementation Notes:**
- **HardwareDetector Integration**: Leverage existing comprehensive API for M2 Ultra optimization
- **GitHub Releases Strategy**: Use exclusive GitHub releases (not LFS) for <2GB components
- **Model Strategy**: Bundle only essential models; users download larger Ollama models in-app
- **HuggingFace Access**: Team token already configured in `config/credentials.yaml`
- **No Code Signing**: Manual notarization process will be needed initially

### **Ready to Execute:**
âœ… All questions answered and clarified
âœ… Current system analyzed and understood  
âœ… Infrastructure strategy confirmed
âœ… Hardware detection API verified
âœ… Build process analyzed
âœ… Scope and timeline agreed upon

**ðŸš€ READY TO BEGIN PHASE 1: INFRASTRUCTURE SETUP**

---

This updated plan ensures a bulletproof installation experience where every component is verified to work before completion, while providing intelligent hardware-based optimization and seamless Obsidian integration.
