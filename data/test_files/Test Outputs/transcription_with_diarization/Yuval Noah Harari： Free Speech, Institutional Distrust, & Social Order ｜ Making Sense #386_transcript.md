---
title: "Transcript of Yuval Noah Harari： Free Speech, Institutional Distrust, & Social Order ｜ Making Sense #386.mp3"
---

## Metadata

- **Filename**: Yuval Noah Harari： Free Speech, Institutional Distrust, & Social Order ｜ Making Sense #386.mp3
- **File Path**: /Users/matthewgreer/Projects/Knowledge_Chipper/data/test_files/Test Inputs/Yuval Noah Harari： Free Speech, Institutional Distrust, & Social Order ｜ Making Sense #386.mp3
- **File Size**: 59.87 MB
- **File Type**: .MP3
- **Duration**: 43:35
- **Audio Codec**: mp3
- **Sample Rate**: 48000 Hz
- **Channels**: 2
- **Model:** small
- **Device:** auto
- **Generated:** 2025-08-23T12:11:22.049603

---

## Related Documents

[[Yuval Noah Harari： Free Speech, Institutional Distrust, & Social Order ｜ Making Sense #386_summary|View Summary]]

## Full Transcript

**00:00 - 00:30** You've all know Harari. Thanks for joining me again. It's good to be here again in, you know, in a real space together. Yeah. This is, you are my first interview in this studio, which is auspicious because we share so many interests. We have struggled for years to talk about meditation and you think we might get there this time. Yeah. I'm determined at least to say at least something about meditation this time. Yeah. Well, it's, there's so much going on in the world that it's, it's always a challenge to get to that topic.

**00:30 - 01:00** Let us connect that when we can talk about Nasrallah and meditation, I think there are many links there. Right. Worth exploring. As counterintuitive as that sounds. Yeah. I mean, you know, if meditation is not related to the world and to the art, to reality, it's, it's worthless. That's true. Yeah. I guess I, well, I feel like I'm, I'm perhaps selling our audience short in thinking that they don't have the bandwidth to think about it, given all the chaos and given, given your expertise that is so relevant to so much of the chaos.

**01:00 - 01:30** You just mentioned Nasrallah. So the time we're recording this, it was just announced that Israel killed Hassan Nasrallah, who's the, who was the head of Hezbollah, which we'll talk about perhaps in the, so I want to focus what you've done in your recent book, Nexus, which is wonderful and here. And perhaps you can say how this relates to your two other big books.

**01:30 - 02:00** Sapiens and Homo Deus. So what is, how do you view the project that you've? So it starts basically where Sapiens and Homo Deus ended. In Sapiens, I covered how this insignificant ape from a corner of Africa took over the world. And in Homo Deus, I explored what could be the potential future of us and of our products and creations here on earth. And Nexus starts

**02:00 - 02:30** with a key question about both the past and the future, which is if humans are so wise, why are we so stupid? Like, you know, we've reached the moon and we split the atom and we can decipher DNA, but we are on the verge of destroying ourselves in so many different ways. It could be ecological catastrophe. It could be a world war, a nuclear war. We are producing the most powerful technology

**02:30 - 03:00** in history, AI, which might quite easily get out of our control and enslave or destroy us. And we know all that and yet we keep doing it. So what's happening? And so many mythologies and theologies throughout history said that the blame is that something is wrong in human nature, that we are flowed, deeply flowed. And I don't think that this is the right answer.

**03:00 - 03:30** The problem is not in our nature. The problem is in our information. If you give good people bad information, they make bad decisions. It's as simple as that. And so then the question becomes, why are we flooded with bad information? Why is it that after thousands of years of history, of developing sophisticated networks of information and communication,

**03:30 - 04:00** our information is not getting any better? I mean, at the present moment, you can say that humans have the best, the most sophisticated information technology in history and we are losing the ability to even talk with each other and to listen and to hold a reasonable conversation. So what's happening? That's the key question of Nexus. And it explores the history of information and of information networks.

**04:00 - 04:30** It takes another look at history, but from the viewpoint not of humanity, but of information. And for instance, I look at our Nexus, looked at the history of democracies and dictatorships. Not as we usually think about them as different ethical systems that believe in different ideals, but as different information networks and how information flows differently in a democracy and in a dictatorship.

**04:30 - 05:00** In a dictatorship, you know, there is one hub where all the decisions are being made. So all the information flows to and from that single center. And a democracy is a distributed information system in which decisions are being made in many different places. And much of the information never passes through the center. Like if you think about the United States, so you have the center at Washington in Washington, but so many decisions

**05:00 - 05:30** are made elsewhere, like here in Hollywood in Los Angeles. And most information never passes through the center. And you can think about the historical struggle between democracy and dictatorship in terms of different models of information flows. I want to pass over that ground again, because what you're saying is pretty counterintuitive and it's very interesting. So because people think about democracy and dictatorship,

**05:30 - 06:00** as this kind of binary that are categorically distinct and you're placing them on a continuum of information flow. Let's add here what you call the naive view of information, because there's a sense that more information is an intrinsic good.

**06:00 - 06:30** People who are running our social media regimes, the idea that if you could just let all ideas collide and remove every point of friction from the flow of information and amplify anything, however, a market or the dynamics of any internet business chooses to amplify it. There's it's just the principle. You know, people have these phrases in their minds, your sunlight is the best disinfectant, right? So let's just expose everything.

**06:30 - 07:00** And we're going to be fine, right? And any effort to steer this information flow is by its very nature sinister. It is edging us toward the totalitarian side of this information continuum. So how do you react to that? This is so naive. This is so disconnected from reality, from history. You think that you flood the world with information and the truth will just rise

**07:00 - 07:30** to the surface. It won't. It will sink to the bottom. Information isn't truth. Most information is junk. It's like thinking that more food is always good for you. The more you eat, the more healthy you will be. That's the same thing. No, I mean, yes, you need some food to survive. But if you just keep eating, it will not be good for you, especially if you keep eating junk food. And the world basically needs an information diet. And, you know, the truth is

**07:30 - 08:00** a subset of information and a very small subset, because the truth, first of all, it's very costly. If you want to write or to produce a truthful account of something, of the Roman Empire, of the economic crisis, whatever, you need to invest a lot of time and effort and money in looking for evidence and fact checking and analyzing. Like, I don't know if you want to know something that happened in the Roman Empire.

**08:00 - 08:30** But they go to university to study for at least 10 years before they become professional historians. You learn Latin and Greek and how to read ancient handwriting and how to do these archaeological excavations. And even if you found a document from the Roman Empire and you know Latin and you can read it, maybe it's just propaganda. Just because Caesar says that the enemy had 100,000 soldiers, it doesn't mean they actually had 100,000 soldiers. So how do you evaluate information?

**08:30 - 09:00** The truth is very costly. Fiction, on the other hand, is very cheap. You just write the first thing that comes to your mind. The truth is also very complicated. Often it's complicated because reality is complicated. Whereas fiction can make it as simple as you would like it to be. And people tend to prefer, in most cases, simplicity over complexity. So this is another disadvantage. So you're pointing out there an asymmetrical relationship between truth

**09:00 - 09:30** and fiction, which redounds to the advantage of fiction in this friction-free environment. And with the third advantage of fiction, the truth is sometimes, not always, but the truth is sometimes painful. You know, from the personal relationships that we often don't want to know the truth about how we treat the other people in our lives. This is why we need to go to therapy for many years to acknowledge the reality. You know, all the way to entire nations, our entire cultures,

**09:30 - 10:00** if you run for elections in the US or in Israel or anywhere else, and you just tell people the truth, the whole truth, and nothing but the truth, I mean, an Israeli politician who would just tell the truth about the Israeli-Palestinian conflict is not likely to gain many votes that way. You need at least some dose of fiction, of mythology to make it more attractive, more pleasant for the voters. Well, it's already so unpleasant. I've shuddered to think what the truth is.

**10:00 - 10:30** But we'll get there. So again, the truth is it's costly. It's complicated. It's sometimes painful. Fiction is cheap. It's simple. You can make it as attractive as you'd like it to be. So in a completely free market of information, truth will lose. You have to tilt the balance in favor of truth by building institutions like courts, like newspapers, like universities, like research centers,

**10:30 - 11:00** that make the effort to produce and to protect the truth. And when people attack these institutions, they often claim that they are liberating people from the yoke of these elite institutions and conspiracy and so forth. But no, when you destroy all trust in these institutions, you're paving the way for dictatorship. If society needs institutions,

**11:00 - 11:30** and democracy works on trust. But if you destroy all trust, the only alternative left to hold society together is with terror, which is what dictatorships do. So this is the game of many would-be dictators. They systematically destroy all trust in the institutions that are our main access to truth and knowledge. And then when all these institutions are gone, then the

**11:30 - 12:00** only alternative left is a dictatorship.

**12:00 - 12:30** You hear things from people who went to study history for 10 years, and then they come up with the most simplistic views of reality. So let's stay at the 30,000-foot level. The experts in many institutions have heaped shame upon their own heads in recent years. But the reaction is not to destroy the institutions. I mean, this is why we need two things. First of all, we need several institutions, not just one, so they keep each other in check.

**12:30 - 13:00** I mean, the basic assumption is humans are fallible. Institutions are composed of humans. So all institutions are fallible. They can make mistakes. They can be captured. They can be corrupted. And therefore you need several institutions to keep each other in check. So if one institution is really corrupted, you can go to the courts or you can expose it in newspapers or in other media or whatever. And secondly, every institution needs a self-correcting mechanism. This is the sign of a good institution that it has

**13:00 - 13:30** mechanisms inside the institution to identify and correct its own mistakes. This is, again, a key difference between democracy and dictatorship. Dictatorship has no self-correcting institution. There is no mechanism in Russia that can expose and correct Putin's mistakes. But democracy is all about self-correction, that the basic mechanism of elections is that every four years or so you can say, "Oh, we made a mistake. Let's try

**13:30 - 14:00** something else." But of course, this every mechanism like this is itself fallible. Elections can be rigged. Like we just had elections in Venezuela and the Venezuelan people said, "Okay, we made a mistake with Chávez and Maduro. Let's try something else." But because Maduro is in power, he rigged the election. He said, "No, no, no, I won." And this is also, of course, very, very relevant to what's happening in the upcoming elections in the United States because the greatest danger for democracy

**14:00 - 14:30** is in a democracy you give power to someone for four years on condition that they give it back. And there is always the danger, what if they don't give it back? So giving power to somebody that you have good reasons to suspect that he will not give it back, very dangerous. So again, elections are not enough. You also need free media. You also need free quotes. Now people ask, "Okay, so what if all these institutions are corrupted?" Then bad luck.

**14:30 - 15:00** It's perfect. If all the institutions of your society has been corrupted and taken over and all the self-correcting mechanisms are disrupted, dysfunctional, very bad news, society collapses. Hopefully, we don't reach that point. And it's very important to try. And the solution is not to lose trust.

**15:00 - 15:30** One of the key problems I see today in the world is that you have an extremely cynical view of humans and of human societies spreading both on the right but also on the left. This is something that the extreme left and the extreme right agree about. They have an extremely cynical view of humans and of reality. They say that the only reality is power that all socially

**15:30 - 16:00** interactions, all human interactions are actually power struggles, that all human institutions are just conspiracies to gain power, that journalists, scientists, historians, judges, politicians, these are just conspiracies to gain power. Whenever somebody tells you something, you shouldn't ask, "Is it true?" Because nobody cares about the truth. This is naive. They would tell you, "No, this is a power play.

**16:00 - 16:30** Who benefits?" Whose privileges are being served? Whose interests are being served? This is something you hear from Marxists and from Trumpists. This is something that Donald Trump agree with Karl Marx, at least on that, that everything is just a power struggle. And if you think like that, all trust collapses and the only thing that is left standing, that can remain standing, is a dictatorship, which indeed assumes that everything is just power.

**16:30 - 17:00** Now, the important thing to realize is this is not just extremely cynical, this is just wrong. People are not these power crazy demons that care only about power. Even powerful people really care about the truth, at least some of them. Well, even I would just add, I totally agree with you, but I would add as a footnote to that cynicism, even if the cynical take were true,

**17:00 - 17:30** incentives are not perfectly aligned. So even in a rivalry of people seeking power, the kinds of conspiracies and collaborations and Orwellian star chambers rarely exist the way populists imagine. You take Elon Musk and Donald Trump.

**17:30 - 18:00** They have a very high opinion of themselves and with not necessarily the same goals in life and in the world, even if they can ally themselves for some time around a certain common interest, in the long run, it will be very, very difficult to keep this alliance. To say nothing of the people who are not aligned with them. There's a fascinating tension between the self-correcting mechanism that would deliver

**18:00 - 18:30** truth and the self-correcting mechanisms that would deliver order. There's this trade-off between truth and order that you describe in the book. Let's cycle on that for a minute. Okay, that's very important because if we think about human societies really as information networks, so the question is, what do these networks produce? And to function, they need to produce two different things, not just one. They need to produce

**18:30 - 19:00** both truth and order. A system that just ignores the truth completely will collapse. It will sooner or later encounter reality and will collapse. But also a system which is only interested in the truth will not be able to maintain order because it's easier to maintain order with fiction and with fantasy and with mass delusions.

**19:00 - 19:30** But I want to just capture people's confusion here. We just spoke about the tension between truth and fiction as though fiction were by definition invidious and something to be canceled. What you're saying now is that we need certain fiction. It can't be purely truth-seeking. Fiction is very efficient in creating order. The main thing is that it's complicated.

**19:30 - 20:00** There's lots of trade-offs.

**20:00 - 20:30** It's a simple as that. On the other hand, to produce an atom bomb, just knowing the fact of physics is not enough. You need millions of people to cooperate on the project. If you have a single physicist, she's the most brilliant physicist in history, and she knows that E equals mc2 and all the secrets of quantum mechanics and whatever,

**20:30 - 21:00** she cannot produce an atom bomb by herself, working in her garage or something. You need people to mine uranium, you know, thousands of kilometers away. You need engineers and workers to build the nuclear reactor. You need people to produce food. So all these workers and physicists have something to eat. How do you get millions of people to cooperate on the project? If you just tell them the facts of physics, E equals mc2. Now, now get on with it. It doesn't work. So what?

**21:00 - 21:30** So just because E equals mc2, we should now work on building this atom bomb? No. This is where ideology and mythology and fictions come into the picture. You usually convince millions of people to work on a project together by telling them some ideology or some mythology. And here, the facts don't matter so much. If you try to build a very powerful ideology and you ignore the facts, your ideology is still likely to explode with

**21:30 - 22:00** a very, very big bang. And in most cases in history, the people who are experts in nuclear physics, for instance, get their orders from the people who are experts in Shiite theology or in Jewish theology or in communist ideology or in Nazi ideology. It's the people who are experts in the truth usually get orders from the people who are experts in order.

**22:00 - 22:30** And this is something that very often scientists and engineers don't understand, that they work on AI and they think that the scientists and the engineers will decide what to do with it. But no, once you produce this very powerful technology because you know the facts about the world, then you will get the people who are experts in mythology and theology coming in and telling you, thank you very much for

**22:30 - 23:00** producing this very powerful technology. Now we will decide what to do with it. Is there a truly benign and wise version of this? Because what you seem to be describing is yet another reason for cynicism and distress. So this is important. Now, it's very hard to create large scale societies without any fictions. Even money is a fiction. Even, you know, think about what is the last thing that still holds American society together.

**23:00 - 23:30** What is the last thing that Republicans and Democrats still agree on? It's the dollar. And even this is under attack, you know, from cryptocurrencies and so forth. But almost the last story that still holds the place together is that everybody agrees on the value of a dollar, which is just a fiction. But fictions are... Sorry, I just want to drill down on this a little bit because I think we hit this in a previous conversation. There's something a little confusing about your use of the word fiction here because fiction in any kind of

**23:30 - 24:00** context where we're talking about the truth sounds intrinsically pejorative, right? So like this is... there's truth and then there's fiction. It's not pejorative. It's just... You're talking about convention. So something that's conventionally constructed. Something that comes out of the human imagination and not from reality. I mean, the value of the dollar is purely an imaginary reality. Exactly. The paper, the dirty paper in your pocket. And most dollars are not even paper. They're just digital tokens in computers. They have no objective value. They have value only in our imagination.

**24:00 - 24:30** In this sense, the dollar is a fiction. And another big question comes. So is everything just a conspiracy? Everything just a fiction? And the key thing is that fictions can be extremely valuable and positive provided you acknowledge they are fictions. I don't think that the dollar is a bad thing. I don't think that the fictions

**24:30 - 25:00** holding society together are a bad thing as long as you acknowledge the reality that this is a man made imaginary thing. And this is important because then you can correct it. Then you can make amendments in it. Let's compare two texts that are foundation texts for holding human society together. The Ten Commandments and the US Constitution. I have a preference. Both are fictional in the sense that they came out of the human imagination.

**25:00 - 25:30** But one text refuses to acknowledge this reality. And the other text is fully honest about it. So the Ten Commandments, they start with I am your Lord God. This text, it claims to be written by God, not by any human, which is why it contains no mechanism for correcting its errors. And if some of our listeners are outraged errors in the Ten Commandments,

**25:30 - 26:00** what could possibly be wrong with Don't Kill and Don't Steal? I don't think I have those listeners. You give me too much credit. Yes, but maybe for the one or two are still left out there. Notice if you read, for instance, the 10th commandment that it endorses slavery. The 10th commandment says that you should not covet your neighbor's house or field or slaves, which implies that God is perfectly OK with people holding slaves. It's just God

**26:00 - 26:30** doesn't like you. They like it when you covet the slaves of your neighbors. No, these are his slaves. Don't covet them. Now, because the text doesn't recognize that this is the creation of the human imagination, there is no 11th commandment, which says, well, if you discover something wrong in the previous 10 Commandments by a two third majority, you can vote on changing commandment number 10. No mechanism. So we still have the same text.

**26:30 - 27:00** From the Iron Age until today. Now, the US Constitution, it's also a foundational text, which gives instructions for people to how to manage their society. It also came out of the human imagination. It's not it's not an objective reality. It's also, in this sense, a fiction. But it is honest. It starts with we, the people. We, the people wrote this text. And because we are fallible human beings, maybe we

**27:00 - 27:30** made some mistakes like endorsing slavery. So we also include in this text a mechanism to amend it to identify and correct its own mistakes. It's not easy, but it can be done and it has been done. So fictions can be extremely valuable. We need them. We cannot have a large scale society without them, but they should be honest about their own fictional nature, which gives us the ability to identify

**27:30 - 28:00** and correct our mistakes or the mistakes of our ancestors. But there's something intrinsically conservative about this picture, because it's admitting that something is a fiction or a convention is not to say that you should want to revise it impetuously. Absolutely not. It's very good that very few people try to rethink the convention about whether to drive on the left side or the right side of the road on a daily basis.

**28:00 - 28:30** It's an arbitrary decision. It's clearly arbitrary, but it's crucially important that we all, once we've decided that we not keep rethinking it. And there are many things like that. And so this distrust in institutions, that what has grown so corrosive is the sense that the appropriate response to each of the errors, however embarrassing they have been of late, is to break fully with the institutions and in some sense,

**28:30 - 29:00** reinvent civilization on your own. You find some place to stand where you can reboot from. And that actually seems to be, I mean, obviously there's a populist version of this, which we can talk about. I think we should talk about populism, but this message seems to be coming from on high. I mean, you mentioned Donald Trump and Elon Musk as prime offenders. They're prime offenders on this very point. They so distrust in our institutions.

**29:00 - 29:30** It's coming from the right and from the left. It's the populist position. It's the Marxist position. Let's destroy the old world and create a new world in its place. This is in the international, in the high, how do you call it, of communism. It's also on the populist right. And as a historian, I tend to be conservative in the deep sense of the word, in the Berkian sense of the word. I mean, what you saw recently all over the world,

**29:30 - 30:00** is the suicide of conservative parties, that they abandoned the conservative values and became revolutionary parties. Like the Republican Party today in the United States is a revolutionary party, revolutionary in the sense. Not just that. It says that, you know, all the institutions are rotten. They cannot be reformed. We just need to destroy all of it and start again, which I mean, people can say, this is true. This is false. Let's leave that aside. But just look at the structure of it.

**30:00 - 30:30** This is what revolutionary parties look like. They say things are so corrupted. Things are so out of order that the only thing left to do is to destroy all the existing institutions and start from scratch, which was the Leninist position, the Bolshevik position a hundred years ago. And now it's the position of many so-called conservative parties that the traditional insight of conservatism is that, yes, institutions are flawed. Institutions can be corrupted.

**30:30 - 31:00** But it takes generations to build a functioning society, a functioning institution. Humans don't really have the capacity to understand the full complexity of reality and to invent a perfect society from scratch. It just can't be done. Every time we try to do it, it leads to disaster. Even worse than the things that we try to correct. You cannot create a perfect society.

**31:00 - 31:30** Move more slowly, be more respectful of the existing institutions and traditions. They need correction. They need amendment. They need improvement, but just destroying them completely and starting from scratch. I mean, you have hundreds of years of kind of previous corrections from real things that happened in history that are baked into the system. Be very careful before you throw all of it out and try to

**31:30 - 32:00** start from scratch. Okay. So what do we do about social media given that picture? What advice do you have for the correct and the obvious pathology we see here? If you could give advice to Elon Musk or Mark Zuckerberg, I mean, one thing or two things, corporations should be liable for the actions of their algorithms. And only humans have freedom of speech, bots and algorithms.

**32:00 - 32:30** Do not have freedom of speech and they should never masquerade as humans. So these are the two main things that are needed to correct social media. So they're publishers. These platforms should be viewed as publishers and their algorithm. The tuning of the algorithm is an editorial choice. Absolutely. Strangely think about it, but one of the first jobs that was fully automated was not taxi drivers. It was not textile workers.

**32:30 - 33:00** It was editors, news editors. It's amazing to think about it. It was automated. The job that once belonged to Lenin and Mussolini is now being done by algorithms. I mean, Lenin, before he was Soviet dictator, he was editor of a newspaper, Iskra and Mussolini. Also, he was to power from being editor of the newspaper Avanti. So this was like the promotion scale, the promotion ladder, editor of a newspaper, editor of the country. And this is for a good reason.

**33:00 - 33:30** News, they sit at one of the most important junctions in society. They shape the conversation. They decide what people would be aware of, what people would be discussing. And this is one of the most important positions in society. And now it's been taken over by algorithms. Because again, in Iskra, it was Lenin who decided what would be the top story of the day, what would be the main headline.

**33:30 - 34:00** And on Facebook, it's an algorithm deciding what is at the top of your feedback, of your news feed. But both of those sound bad. So if you're going to give people a choice between Lenin and an algorithm, they're going to take the algorithm. So the thing is that in not in a dictatorship, in a democracy, newspapers and other news outlets are liable for their decisions. Like if the editor of the New York Times decides to publish some conspiracy theory or fake news at the

**34:00 - 34:30** front page of the New York Times, he cannot hide or she cannot hide behind the argument. But free speech, there are some people who believe it's true. So I put it on the front page of the New York Times. No, your job as editor is not just to put something random there or something that would please people. Your job is to fact check and to take responsibility for these decisions and to make sure that if you publish something on the front page of the New York Times,

**34:30 - 35:00** you better be sure that this is accurate and this is responsible. And if you don't know how to do it, then you're in the wrong job. And what again, I will tell to Facebook, to Twitter, to TikTok. Be very, very careful before you censor human users. I mean, if a human user decided to publish even a lie, even the fake news, even a conspiracy theory, I would be extremely careful before I shut

**35:00 - 35:30** down their account or send those in. But if my algorithm, as the corporation, then decides to promote this particular piece of fake news or this particular conspiracy theory, this is on me. This is on the company, not on the user. The promotion is the amplification, not the fact that it exists on the network in the first place. Absolutely. They can't possibly prevent, and they have billions of pieces of content arriving every

**35:30 - 36:00** day. So they can't guarantee that there will be no malicious lies or even child pornography on their network. And it's the same way that people send letters to the New York Times every day. So it's not the position of the job of the New York Times to censor them. But don't publish them on your front page unless you're sure that you did. And sometimes even make mistakes. But still, your job is to fact check and to think about the implications of these

**36:00 - 36:30** stories and then take a very responsible decision about what you choose to promote. The other thing is that social media should reserve freedom of speech to human beings, not to bots and to algorithms. And in particular, we should ban fake humans, counterfeit humans. If a bot pretends to be a human, we should know about it. Like if you see that some story on Twitter,

**36:30 - 37:00** it contains a lot of traction, a lot of traffic. And you think to yourself, oh, lots of humans are interested in this story. This must be important. I also want to know what everybody's talking about. And you also start, you click on it. You also stopped commenting on it. But actually, the entities that at least originally pushed this story to the top of the conversation, they were not humans. They were bots.

**37:00 - 37:30** Working in the service of Putin or whoever. This is wrong. We should not have fake humans shaping the human conversation. Democracy is a conversation. Imagine it as a group of people standing in a circle, talking with each other. Suddenly, a group of robots join the circle and talk very loudly, very pressuratively. They pretend to be humans and you don't know.

**37:30 - 38:00** Tell who are the humans and who are the robots. The conversation breaks down. To be clear, you're not against bots of various kinds. You just think they should be declared as bots. Absolutely. Again, if you have a medical bot and you want to consult with that bot about some medical condition, I mean, soon we'll have AI doctors with capabilities far beyond human doctors. I'm not against that. They can improve healthcare dramatically. They can help provide better healthcare for billions of people.

**38:00 - 38:30** But when I talk with a non-human entity, I want to know that this is a non-human entity, that I'm not talking with a human being. They are welcome to join the conversation on condition that they don't masquerade as humans. What you're arguing for essentially, and I think this is a phrase you use in the book, that what we need are benevolent networks that have a fiduciary responsibility to their users. It's a very old principle.

**38:30 - 39:00** You can't invent anything new in this respect. If you think about your doctor, or your therapist, or your accountant, or your lawyer, for centuries, we already had these regulations and understanding that they have access to extremely private information, to potentially explosive information about us that could maybe ruin our life. They have a fiduciary duty to use that information only for our

**39:00 - 39:30** interests, except in very extreme circumstances when there is a crime or something. But our doctor, for instance, cannot take my personal information and sell it to third parties for profits. The same principle should hold with our relationship with the high-tech giants. I mean, they should have the same responsibilities. How do you think about this trade-off between efficiency and inefficiency?

**39:30 - 40:00** Efficiency sounds like it's a bug, but as you point out in the book, there are places where it's a feature because it's a bulwark against totalitarianism. Yet we want a certain kind of efficiency so as to be able to find malicious actors and terrorists, et cetera. How do you view that in a reasonably well-functioning democracy that has institutions that are error-correcting both with respect to truth and with respect to order?

**40:00 - 40:30** If you could get your hands on the dial of efficiency, how would you tune it? That's the democratic conversation. We avoid the extremes and find the middle path, and you're bound to make mistakes, so keep correcting your mistakes. It's not like there is a magic bullet that solves it once and for all. What is the right level of surveillance? What is the right level of immigration? This is what we have the democratic debate for. If you go for an extreme position,

**40:30 - 41:00** you know, humans have a right to immigrate to anywhere they like in as huge numbers as they like. This is completely unfeasible. So again, how many immigrants a country want to absorb and under what conditions? Let's discuss. Different people have different views. I don't think that people who want a more strict immigration policy, this immediately turns them

**41:00 - 41:30** into fascists and Nazis. Similarly, people who want more lenient immigration policies, less restrictive, that doesn't turn them immediately into traitors who want to destroy the country. Let's have a conversation and try this policy and try that policy. It should not be a kind of all-out war between good and evil. The same goes for the level of surveillance and the same goes for the level of free speech. In all these cases, we need to

**41:30 - 42:00** find the middle path and it's difficult. We need to start with the assumption that we are not infallible and that other people might have good ideas about these questions. Let's take this general framework that you've sketched in your book and look at a few current events. There really is too much to talk about, but we have the US election. We have the ongoing war in Ukraine. We have the ongoing war between Israel

**42:00 - 42:30** and now on at least two fronts, Israel and her enemies. Let's start with the US election. How do you view our circumstance here? We really are the poster child for a lot of the dysfunction you described more generically in your book. There's just a pervasive sense that I think social media doesn't

**42:30 - 43:00** fully explain it, but it certainly has amplified the problem. There's a pervasive sense that we've lost the capacity to speak to one another about rather fundamental issues. We're just hurtling towards some political catastrophe here. We have an election, which however it goes, it's quite plausible to imagine that half the country won't believe the results given what has happened in recent years.

**43:00 - 43:30** Let's go back from the brain care. Historically, there are two big dangers for the survival of democracies. You can see both of them now in the US. One big danger is what we discussed earlier.

**43:30 - 44:00** You

